version: "3.9"

services:
  llm-service:
    build: ./llm_service
    image: vllm-qwen3-ai:latest
    container_name: llm-service
    ports:
      - "8005:8005"  # host:container port
    environment:
      - CUDA_VISIBLE_DEVICES=1
      - MODEL_PATH=./models
      - TRUST_REMOTE_CODE=true
      - N_THREADS=4
      - GPU_ID=0
    volumes:
      - ./llm_service:/app
    command: uvicorn main:app --host 0.0.0.0 --port 8005
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    networks:
      - docker-network

networks:
  docker-network:
    external: true
